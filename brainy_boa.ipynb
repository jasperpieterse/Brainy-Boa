{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neat\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from config import *\n",
    "import visualize\n",
    "import NEAT\n",
    "from snake_class import SnakeGame\n",
    "\n",
    "#Set the local directory\n",
    "local_dir = os.getcwd()\n",
    "neat_config_path = os.path.join(local_dir, Paths.NEAT_CONFIG_PATH)\n",
    "config_path = os.path.join(local_dir, Paths.CONFIG_PATH)\n",
    "\n",
    "# Load configuration into a NEAT object.\n",
    "neat_config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        neat_config_path)\n",
    "\n",
    "current_game_instance = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genome(genome, config): \n",
    "    \"\"\"\n",
    "    Fitness function to evaluate single genome, used with ParallelEvaluator.\n",
    "    \"\"\"\n",
    "    net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    print(current_game_instance)\n",
    "    fitness = current_game_instance.simulate_headless(net)  # Evaluate the genome in a headless simulation.\n",
    "    return fitness                          # For the ParallelEvaluator to work, the fitness must be returned.\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    \"\"\"\n",
    "    Fitness function used to assign fitness to all genomees. This is different from eval_genome in that \n",
    "    it does not use the ParallelEvaluator and thus goes through each genome in the population one by one.\n",
    "\n",
    "    Args:\n",
    "    genomes (list of tuples): List of (genome_id, genome) tuples.\n",
    "    config (neat.Config): NEAT configuration settings for network creation.\n",
    "    \"\"\"\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config) # Create a neural network from the genome.\n",
    "        fitness = current_game_instance.simulate_headless(net)  # Evaluate the genome in a headless simulation.\n",
    "        genome.fitness = fitness  # Assign the fitness to the genome.\n",
    "\n",
    "\n",
    "def run_NEAT(config_file, n_generations=10):\n",
    "    \"\"\"\n",
    "    Run the NEAT algorithm to find the best performing genome.\n",
    "    \"\"\"\n",
    "    global current_game_instance\n",
    "    # Load configuration into a NEAT object.\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                            neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                            config_file)\n",
    "\n",
    "    #Set results directory\n",
    "    if not os.path.exists(f\"{Paths.RESULTS_PATH}/checkpoints\"):\n",
    "        os.makedirs(f\"{Paths.RESULTS_PATH}/checkpoints\")\n",
    "\n",
    "    # Create the population\n",
    "    p = neat.Population(config)\n",
    "\n",
    "    # Add statistics reporter to the population\n",
    "    stats = neat.StatisticsReporter()\n",
    "    p.add_reporter(stats)\n",
    "\n",
    "    # Show progress in the terminal and add a checkpointer\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    p.add_reporter(neat.Checkpointer(10, filename_prefix=f\"{Paths.RESULTS_PATH}/checkpoints/population-\"))\n",
    "\n",
    "    # Add a parallel evaluator to evaluate the population in parallel.\n",
    "    parallel_evaluator = neat.ParallelEvaluator(multiprocessing.cpu_count(), eval_genome) #parallelized fitness function\n",
    "\n",
    "    # Run the NEAT algorithm for n generations\n",
    "    winner = p.run(parallel_evaluator.evaluate, n=n_generations)  \n",
    "\n",
    "    # Visualize statistics and species progression over generations.\n",
    "    visualize.plot_stats(stats, ylog=False, view=True, filename=f\"{Paths.RESULTS_PATH}/fitness_graph.png\")\n",
    "    visualize.plot_species(stats, view=False, filename=f\"{Paths.RESULTS_PATH}/species_graph.png\")\n",
    "\n",
    "    # Save the winner.\n",
    "    with open('results/winner_genome', 'wb') as f:\n",
    "        pickle.dump(winner, f)\n",
    "\n",
    "    return winner, stats\n",
    "\n",
    "def run_NEAT_repeated(config_file, n_runs = 1, n_generations = 10):\n",
    "    \"\"\"Runs multiple instances of the NEAT algorithm and returns the winners and statistics of each run.\"\"\"\n",
    "    global current_game_instance\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                            neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                            config_file)\n",
    "\n",
    "    # Ensure the results directory exists.\n",
    "    if not os.path.exists(f\"{Paths.RESULTS_PATH}/checkpoints\"):\n",
    "        os.makedirs(f\"{Paths.RESULTS_PATH}/checkpoints\")\n",
    "\n",
    "    #Clear the output directory\n",
    "    shutil.rmtree(Paths.RESULTS_PATH)\n",
    "\n",
    "    winners = []\n",
    "    stats_list = []\n",
    "\n",
    "    for i in range(n_runs):  # Run the NEAT algorithm n times\n",
    "        print(f\"Running NEAT algorithm, run {i}\")\n",
    "        p = neat.Population(config)\n",
    "        stats = neat.StatisticsReporter()\n",
    "        p.add_reporter(stats)\n",
    "\n",
    "        if not os.path.exists(f\"{Paths.RESULTS_PATH}/checkpoints/run{i}\"):\n",
    "            os.makedirs(f\"{Paths.RESULTS_PATH}/checkpoints/run{i}\")\n",
    "        p.add_reporter(neat.Checkpointer(1, filename_prefix=f\"{Paths.RESULTS_PATH}/checkpoints/run{i}/population-\"))\n",
    "\n",
    "        parallel_evaluator = neat.ParallelEvaluator(multiprocessing.cpu_count(), eval_genome)\n",
    "        winner = p.run(eval_genomes, n = n_generations)\n",
    "\n",
    "        winners.append(winner)\n",
    "        stats_list.append(stats)\n",
    "\n",
    "        # Save the winner of each run\n",
    "        with open(f'{Paths.RESULTS_PATH}/checkpoints/run{i}/winner_genome', 'wb') as f:\n",
    "            pickle.dump(winner, f)\n",
    "\n",
    "        #Print results\n",
    "        print(f\"Run {i} completed, best fitness: {winner.fitness}\")\n",
    "\n",
    "    return winners, stats_list\n",
    "\n",
    "def test_winner(genome, config_path):\n",
    "    \"\"\"Visualizes the genome passed playing the snake game\"\"\"\n",
    "\n",
    "    # Load configuration into a NEAT object.\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        config_path)\n",
    "    \n",
    "    net = neat.nn.FeedForwardNetwork.create(genome, config) # Initialize the neural network from the passed genome.s\n",
    "\n",
    "    # run the simulation\n",
    "    current_game_instance.simulate_animation(net, genome, config) # Simulate the environment with a GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up\n",
    "\n",
    "We will first create an instance of the SnakeGame class and run the game for a few steps to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaselineSnake = SnakeGame()\n",
    "current_game_instance = BaselineSnake\n",
    "\n",
    "update_config('config-neat','DefaultGenome', BaselineSnake.neat_params['input_output']['DefaultGenome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 1  # Number of runs of the NEAT algorithm\n",
    "N_GENERATIONS = 10 # Number of generations for each run of the NEAT algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genome(genome, config): \n",
    "    \"\"\"\n",
    "    Fitness function to evaluate single genome, used with ParallelEvaluator.\n",
    "    \"\"\"\n",
    "    net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    fitness = current_game_instance.simulate_headless(net)  # Evaluate the genome in a headless simulation.\n",
    "    return fitness                          # For the ParallelEvaluator to work, the fitness must be returned.\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    \"\"\"\n",
    "    Fitness function used to assign fitness to all genomees. This is different from eval_genome in that \n",
    "    it does not use the ParallelEvaluator and thus goes through each genome in the population one by one.\n",
    "\n",
    "    Args:\n",
    "    genomes (list of tuples): List of (genome_id, genome) tuples.\n",
    "    config (neat.Config): NEAT configuration settings for network creation.\n",
    "    \"\"\"\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config) # Create a neural network from the genome.\n",
    "        fitness = current_game_instance.simulate_headless(net)  # Evaluate the genome in a headless simulation.\n",
    "        genome.fitness = fitness  # Assign the fitness to the genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NEAT algorithm, run 0\n",
      "Saving checkpoint to results//checkpoints/run0/population-0\n",
      "Saving checkpoint to results//checkpoints/run0/population-1\n",
      "Saving checkpoint to results//checkpoints/run0/population-2\n",
      "Saving checkpoint to results//checkpoints/run0/population-3\n",
      "Saving checkpoint to results//checkpoints/run0/population-4\n",
      "Saving checkpoint to results//checkpoints/run0/population-5\n",
      "Saving checkpoint to results//checkpoints/run0/population-6\n",
      "Saving checkpoint to results//checkpoints/run0/population-7\n",
      "Saving checkpoint to results//checkpoints/run0/population-8\n",
      "Saving checkpoint to results//checkpoints/run0/population-9\n",
      "Run 0 completed, best fitness: 1.2\n",
      "Best run: 0 with fitness:ยง 1.2\n"
     ]
    }
   ],
   "source": [
    "winners_list, stats_list_baseline = run_NEAT_repeated(neat_config_path, N_RUNS, N_GENERATIONS)\n",
    "\n",
    "best_run_idx = np.argmax([winner.fitness for winner in winners_list])\n",
    "print(f\"Best run: {best_run_idx} with fitness:ยง {winners_list[best_run_idx].fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1136",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_winner(winners_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], neat_config_path)\n",
      "Cell \u001b[0;32mIn[2], line 120\u001b[0m, in \u001b[0;36mtest_winner\u001b[0;34m(genome, config_path)\u001b[0m\n\u001b[1;32m    117\u001b[0m net \u001b[38;5;241m=\u001b[39m neat\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mFeedForwardNetwork\u001b[38;5;241m.\u001b[39mcreate(genome, config) \u001b[38;5;66;03m# Initialize the neural network from the passed genome.s\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# run the simulation\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m current_game_instance\u001b[38;5;241m.\u001b[39msimulate_animation(net, genome, config)\n",
      "File \u001b[0;32m~/Physicss/Natural-Computing/Brainy Boa/snake_class.py:485\u001b[0m, in \u001b[0;36mSnakeGame.simulate_animation\u001b[0;34m(self, net, genome, config)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUSE_OBSTACLES:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_obstacle()\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_network(net, genome, node_centers, hidden_nodes)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_fitness()\n\u001b[1;32m    487\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n",
      "File \u001b[0;32m~/Physicss/Natural-Computing/Brainy Boa/snake_class.py:601\u001b[0m, in \u001b[0;36mSnakeGame.draw_network\u001b[0;34m(self, net, genome, node_centers, hidden_nodes)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_connections(net\u001b[38;5;241m.\u001b[39minput_nodes, hidden_nodes, net, genome, node_centers)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_connections(hidden_nodes, hidden_nodes, net, genome, node_centers)\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_connections(hidden_nodes, net\u001b[38;5;241m.\u001b[39moutput_nodes, net, genome, node_centers)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, input_node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(net\u001b[38;5;241m.\u001b[39minput_nodes):\n\u001b[1;32m    604\u001b[0m     center \u001b[38;5;241m=\u001b[39m node_centers[input_node]\n",
      "File \u001b[0;32m~/Physicss/Natural-Computing/Brainy Boa/snake_class.py:525\u001b[0m, in \u001b[0;36mSnakeGame.draw_connections\u001b[0;34m(self, first_set, second_set, net, genome, node_centers)\u001b[0m\n\u001b[1;32m    522\u001b[0m color \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBLUE \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mORANGE\n\u001b[1;32m    524\u001b[0m surf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mSurface((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSCREEN_WIDTH, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSCREEN_HEIGHT), pygame\u001b[38;5;241m.\u001b[39mSRCALPHA)\n\u001b[0;32m--> 525\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m0.3\u001b[39m \u001b[38;5;241m+\u001b[39m net\u001b[38;5;241m.\u001b[39mvalues[first] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m    526\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mline(surf, color \u001b[38;5;241m+\u001b[39m (alpha,), start, stop, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    527\u001b[0m screen\u001b[38;5;241m.\u001b[39mblit(surf, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 1136"
     ]
    }
   ],
   "source": [
    "test_winner(winners_list[-1], neat_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_list, stats_list = NEAT.run_NEAT_repeated(neat_config_path)\n",
    "\n",
    "best_run_idx = np.argmax([winner.fitness for winner in winners_list])\n",
    "print(f\"Best run: {best_run_idx} with fitness: {winners_list[best_run_idx].fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_fitness_baseline = np.mean([np.array(stats.get_fitness_mean())[-1] for stats in stats_list_baseline])\n",
    "std_fitness_baseline = np.std([np.array(stats.get_fitness_mean())[-1] for stats in stats_list_baseline])\n",
    "\n",
    "# Calculate average fitness and standard deviation over all runs\n",
    "average_fitness= np.mean([np.array(stats.get_fitness_mean())[-1] for stats in stats_list])\n",
    "std_fitness = np.std([np.array(stats.get_fitness_mean())[-1] for stats in stats_list])\n",
    "\n",
    "average_fitness= 10.3\n",
    "\n",
    "# Data to plot\n",
    "fitness_means = [average_fitness_baseline, average_fitness]\n",
    "fitness_stds = [std_fitness_baseline, std_fitness]\n",
    "labels = ['NSWE', 'Snake FoR']\n",
    "\n",
    "# Creating the bar plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, fitness_means, yerr=fitness_stds, capsize=5, color=['#c0392b', '#229954'])\n",
    "ax.set_ylabel('Average Fitness')\n",
    "ax.set_title(f'Average Fitness over {Config.N_RUNS} Runs after {Config.N_GENERATIONS} Generations')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(local_dir + '/' + Paths.RESULTS_PATH + '/fitness_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "np.save(local_dir + '/' + Paths.RESULTS_PATH + '/winners_list', winners_list)\n",
    "np.save(local_dir + '/' + Paths.RESULTS_PATH + '/stats_list', stats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# winners_list = np.load(local_dir + '/experiment_1/winners_list.npy', allow_pickle=True)\n",
    "# stats_list = np.load(local_dir + '/experiment_1/stats_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average fitness and standard deviation for winners\n",
    "average_fitness_winners = np.mean([winner.fitness for winner in winners_list])\n",
    "std_fitness_winners = np.std([winner.fitness for winner in winners_list])\n",
    "\n",
    "# Calculate average fitness and standard deviation over all runs\n",
    "average_fitness = np.mean([np.array(stats.get_fitness_mean())[-1] for stats in stats_list])\n",
    "std_fitness = np.std([np.array(stats.get_fitness_mean())[-1] for stats in stats_list])\n",
    "\n",
    "# Data to plot\n",
    "fitness_means = [average_fitness_winners, average_fitness]\n",
    "fitness_stds = [std_fitness_winners, std_fitness]\n",
    "labels = ['Best Genomes', 'All Genomes']\n",
    "\n",
    "# Creating the bar plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, fitness_means, yerr=fitness_stds, capsize=5, color=['#c0392b', '#229954'])\n",
    "ax.set_ylabel('Average Fitness')\n",
    "ax.set_title(f'Average Fitness over {Config.N_RUNS} Runs')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(local_dir + '/' + Paths.RESULTS_PATH + '/fitness_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the best genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get statistics from the best run\n",
    "winner_stats = stats_list[best_run_idx]\n",
    "generations = range(1, Config.N_GENERATIONS + 1)\n",
    "best_fitnesses = [g.fitness for g in winner_stats.most_fit_genomes]\n",
    "avg_fitnesses = np.array(winner_stats.get_fitness_mean())\n",
    "stdev_fitnesses = np.array(winner_stats.get_fitness_stdev())\n",
    "\n",
    "\n",
    "plt.plot(generations, best_fitnesses, color = '#c0392b', label=\"Best Genome\")\n",
    "plt.plot(generations, avg_fitnesses, color = '#229954', label=\"Average\")\n",
    "plt.plot(generations, avg_fitnesses + stdev_fitnesses, color = '#abebc6', label=\"+1 $\\sigma_{std}$\")\n",
    "plt.plot(generations, avg_fitnesses - stdev_fitnesses, color = '#abebc6', label=\"-1 $\\sigma_{std}$\")\n",
    "\n",
    "\n",
    "# plt.title(f\"Best Run ({best_run_idx + 1}) Results\")\n",
    "plt.title(f\"Fitness over Generations of Best Run ({best_run_idx + 1})\") \n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the best snake at different generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_nr_1 = 310\n",
    "generation_nr_2 = 410\n",
    "\n",
    "# Get the best genome at every generation\n",
    "best_genomes = [g for g in winner_stats.most_fit_genomes]\n",
    "\n",
    "genome_1 = best_genomes[generation_nr_1]\n",
    "genome_2 = best_genomes[generation_nr_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_genomes = [g for g in winner_stats.most_fit_genomes]\n",
    "\n",
    "visualize.test_winner(genome_1, config_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.test_winner(genome_2, config_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the best solution of each run separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get statistics from all runs\n",
    "stats = stats_list[best_run_idx]\n",
    "generations = range(1, Config.N_GENERATIONS + 1)\n",
    "\n",
    "# Get the best genome at every generation\n",
    "best_genomes = [[g for g in stats.most_fit_genomes] for stats in stats_list]\n",
    "\n",
    "# Plot the best genome of each run\n",
    "for i, genome in enumerate(best_genomes):\n",
    "    best_fitnesses = [g.fitness for g in genome]\n",
    "    plt.plot(generations, best_fitnesses, label=f\"Run {i + 1}\")\n",
    "\n",
    "plt.title(f\"Best Genome of each Run\")\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.savefig(local_dir + '/' + Paths.RESULTS_PATH + '/best_genomes_each_run.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize speciation of best run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_sizes = np.array(winner_stats.get_species_sizes())\n",
    "num_generations = len(species_sizes)\n",
    "curves = np.array(species_sizes).T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.stackplot(range(num_generations), *curves)\n",
    "\n",
    "plt.title(\"Speciation\")\n",
    "plt.ylabel(\"Size per Species\")\n",
    "plt.xlabel(\"Generations\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_species_fitness = np.array(winner_stats.get_species_fitness())\n",
    "\n",
    "print(total_species_fitness[:, 0])\n",
    "print(species_sizes[:, 0])\n",
    "\n",
    "print(total_species_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_fitness = np.array(winner_stats.get_species_fitness())\n",
    "\n",
    "num_generations = len(species_sizes)\n",
    "\n",
    "\n",
    "for i in range (len(species_fitness[0])):\n",
    "    # Extract the column corresponding to the species\n",
    "    species_data = species_fitness[:, i]\n",
    "    \n",
    "    # Filter out empty strings and convert to float\n",
    "    valid_fitness = np.array([float(x) for x in species_data if x != ''])\n",
    "    \n",
    "    # Get the valid indices to match the generations\n",
    "    valid_indices = np.where(species_data != '')[0]\n",
    "\n",
    "    \n",
    "    # Plot only the valid data points\n",
    "    plt.plot(valid_indices, valid_fitness, label=f\"Species {i}\")\n",
    "\n",
    "plt.title(\"Speciation\")\n",
    "plt.ylabel(\"Species Fitness\")\n",
    "plt.xlabel(\"Generations\")\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the n best solutions over all runs [NOT IMPLEMENTED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats_list[best_run_idx]\n",
    "n_best_genomes =  stats.best_unique_genomes(5)\n",
    "\n",
    "n_best_genomes_fitness = [g.fitness for g in n_best_genomes]\n",
    "n_best_genomes_id = np.argpartition(n_best_genomes_fitness, -3)[-3:]\n",
    "print(n_best_genomes_fitness)\n",
    "print(n_best_genomes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "# Get the n best genomes from all runs\n",
    "all_best_genomes = []\n",
    "for stats in stats_list:\n",
    "    all_best_genomes += stats.best_unique_genomes(n)\n",
    "\n",
    "all_best_fitness = [g.fitness for g in all_best_genomes]\n",
    "n_best_genomes_id = np.argpartition(all_best_fitness, -n)[-n:]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "generations = range(1, Config.N_RUNS + 1)\n",
    "for id in n_best_genomes_id:\n",
    "    genome = all_best_genomes[id]\n",
    "    best_fitnesses = [g.fitness for g in genome]\n",
    "    plt.plot(generations, best_fitnesses)\n",
    "\n",
    "plt.plot(generations, best_fitnesses, 'r-', label=\"best\")\n",
    "\n",
    "plt.title(f\"Best Run ({best_run_idx + 1}) Results\")\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint restoration [DOES NOT WORK PROPERLY FOR NOW]\n",
    "\n",
    "If I restore a checkpoint, and then check the fitness of that population, it does not match up with the graphs above. I am not sure why. I will try to figure it out later, if we will actually need to use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_nr_1 = 18\n",
    "population_1 = neat.Checkpointer.restore_checkpoint(f'results/checkpoints/run{best_run_idx}/population-{generation_nr_1}')\n",
    "\n",
    "genome_tuples = list(iter(population_1.population.items()))   # List of (genome_id, genome) tuples.\n",
    "\n",
    "# Assign a fitness value to each genome\n",
    "NEAT.eval_genomes(genome_tuples, config)\n",
    "\n",
    "# Get the best genome of the generation\n",
    "genomes = population_1.population.values() # List of the genomes after evaluation.\n",
    "best_genome = None\n",
    "for i, g in enumerate(iter(genomes)):\n",
    "    if best_genome is None or g.fitness > best_genome.fitness:\n",
    "        best_genome = g\n",
    "\n",
    "print(f\"Best genome has fitness: {best_genome.fitness}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
